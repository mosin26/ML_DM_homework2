{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Vasiliy Mosin***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a CNN with greedy layer-wise pretraining via Variational Convolutional AutoEncoders implemented in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import *\n",
    "\n",
    "from mldm.net import Net\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "wget -q -nc https://raw.githubusercontent.com/amitgroup/amitgroup/master/amitgroup/io/mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir -p mnist && {\n",
    "    cd mnist;\n",
    "    wget -q -nc http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz &&\n",
    "    wget -q -nc http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz &&\n",
    "    wget -q -nc http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz &&\n",
    "    wget -q -nc http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz &&\n",
    "    gunzip *.gz\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = mnist.load_mnist(dataset='training', path='mnist/')\n",
    "X = X.reshape(-1, 1, 28, 28).astype('float32')\n",
    "\n",
    "X_test, y_test = mnist.load_mnist(dataset='testing', path='mnist/')\n",
    "X_test = X_test.reshape(-1, 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(y, n_classes=10):\n",
    "    onehot = np.zeros(shape=(y.shape[0], n_classes), dtype='float32')\n",
    "    onehot[np.arange(y.shape[0]), y] = 1.0\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = one_hot(y)\n",
    "y_test = one_hot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a little change to the DeepDenseMNISTNet class in order to create Convolutional Autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DeepDenseMNISTNet(Net):\n",
    "    def __init__(self):\n",
    "        self.X_batch = T.tensor4(name='X_batch')\n",
    "        self.y_batch = T.fmatrix(name='y_batch')\n",
    "        self.layers = []\n",
    "        input_l = layers.InputLayer(shape=(None, 1, 28, 28), input_var=self.X_batch, name='Input')\n",
    "        self.layers.append(input_l)\n",
    "        for i, n_units in enumerate([4, 4, 4]):\n",
    "            conv = layers.Conv2DLayer(self.layers[-1], n_units, (3, 3))\n",
    "            self.layers.append(conv)\n",
    "        output_l = layers.DenseLayer(self.layers[-1], num_units=10, nonlinearity=nonlinearities.softmax, name= 'output') \n",
    "        self.layers.append(output_l)\n",
    "        self.net = output_l       \n",
    "        self.predictions = layers.get_output(self.net)\n",
    "        self.pure_loss = T.mean(objectives.categorical_crossentropy(self.predictions, self.y_batch))        \n",
    "        self.prior_params = [theano.shared(np.zeros(shape=param.get_value().shape, dtype='float32'),\n",
    "                name = 'prior%d' % i) for i, param in enumerate(layers.get_all_params(self.net, regularizable=True))]    \n",
    "        self.regularizations = [T.mean((param - prior) ** 2) for param, prior in\n",
    "                                zip(layers.get_all_params(self.net, regularizable=True), self.prior_params)]       \n",
    "        self.regularization = reduce(lambda a, b: a + b, self.regularizations)\n",
    "        self.regularization_coef = T.fscalar('regularization_coef')        \n",
    "        self.loss = self.pure_loss + self.regularization_coef * self.regularization        \n",
    "        self.learning_rate = T.fscalar('learning rate')\n",
    "        params = layers.get_all_params(self.net)\n",
    "        upd = updates.adadelta(self.loss, params, learning_rate=self.learning_rate)\n",
    "        self.train = theano.function([self.X_batch, self.y_batch, self.regularization_coef, self.learning_rate],\n",
    "                                     self.pure_loss, updates=upd)\n",
    "        self.get_loss = theano.function([self.X_batch, self.y_batch], self.pure_loss)\n",
    "        super(DeepDenseMNISTNet, self).__init__()\n",
    "    \n",
    "    def copy_as_prior(self):\n",
    "        for param, prior in zip(layers.get_all_params(self.net, regularizable=True), self.prior_params):\n",
    "            value = param.get_value()\n",
    "            prior.set_value(value)\n",
    "            \n",
    "    def save(self, path):\n",
    "        params = layers.get_all_param_values(self.net)\n",
    "        priors = [ prior.get_value() for prior in self.prior_params ]\n",
    "        p = dict()\n",
    "        for i, v in enumerate(params):\n",
    "            p['param_%d' % i] = v\n",
    "        for i, v in enumerate(priors):\n",
    "            p['prior_%d' % i] = v\n",
    "        return np.savez(path, **p)\n",
    "    \n",
    "    def load(self, path):\n",
    "        with np.load(path) as f:\n",
    "            params = layers.get_all_params(self.net)\n",
    "            param_values = [ f['param_%d' % i] for i in xrange(len(params)) ]\n",
    "            layers.set_all_param_values(self.net, param_values)\n",
    "            for i, prior in enumerate(self.prior_params):\n",
    "                prior.set_value(f['prior_%d' % i])\n",
    "        return self\n",
    "            \n",
    "    @staticmethod\n",
    "    def batch_stream(n, batch_size=32):\n",
    "        n_batches = n / batch_size\n",
    "        for i in xrange(n_batches):\n",
    "            indx = np.random.choice(n, size=batch_size)\n",
    "            yield indx\n",
    "    \n",
    "    def fit(self, X, y, n_epoches = 1, batch_size=32, regularization_coef=1.0e-3, learning_rate = 1.0):\n",
    "        regularization_coef = np.float32(regularization_coef)\n",
    "        learning_rate = np.float32(learning_rate)\n",
    "        n_batches = X.shape[0] / batch_size\n",
    "        losses = np.zeros(shape=(n_epoches, n_batches), dtype='float32')\n",
    "        for epoch in xrange(n_epoches):\n",
    "            #print epoch\n",
    "            for i, indx in enumerate(self.batch_stream(X.shape[0], batch_size=batch_size)):\n",
    "                losses[epoch, i] = self.train(X[indx], y[indx], regularization_coef, learning_rate)\n",
    "            yield losses[:(epoch + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deep_net = DeepDenseMNISTNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deep_net.save('deep-net-0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lozz = []\n",
    "for loss in deep_net.fit(X, y, n_epoches=8, batch_size=512, regularization_coef=1.0e-3):\n",
    "    lozz.append(loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting training curve without pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f61db5cbbd0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFBpEREQkLgoNIiIiEheFBhEREYnL/wc1wyDZ9aqAyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61dcfd4b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lozz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compare it with pretrained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deep_net = deep_net.load('deep-net-0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(Net):\n",
    "    def __init__(self, layer, X_input, p = 0.1):\n",
    "        super(VAE, self).__init__()      \n",
    "        X_in = layers.get_output(layer.input_layer)\n",
    "        in_shape = layer.input_shape\n",
    "        out_shape = layer.output_shape      \n",
    "        self.in_layer = layers.InputLayer(shape=in_shape, input_var=X_in)\n",
    "        self.dropout_l = layers.DropoutLayer(self.in_layer, p = p, rescale=False)\n",
    "        self.encode_l = layers.Conv2DLayer(self.dropout_l, out_shape[1], (3,3), W = layer.W, b = layer.b)\n",
    "        self.decode_l = layers.Deconv2DLayer(self.encode_l, in_shape[1], (3,3))\n",
    "        self.net = self.decode_l\n",
    "        reconstructed = layers.get_output(self.decode_l)\n",
    "        self.reconstructed = reconstructed\n",
    "        self.loss = -T.mean(X_in * T.log(reconstructed) + (1 - X_in) * T.log(1 - reconstructed))\n",
    "        params = layers.get_all_params(self.net)\n",
    "        learning_rate = T.fscalar('learning rate')\n",
    "        upd = updates.adadelta(self.loss, params, learning_rate=learning_rate)\n",
    "        self.train = theano.function([X_input, learning_rate], self.loss, updates=upd, allow_input_downcast=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def batch_stream(n, batch_size=32):\n",
    "        n_batches = n / batch_size\n",
    "        for i in xrange(n_batches):\n",
    "            indx = np.random.choice(n, size=batch_size)\n",
    "            yield indx\n",
    "    \n",
    "    def fit(self, X, n_epoches = 1, batch_size=32, learning_rate = 1.0):\n",
    "        learning_rate = np.float32(learning_rate)\n",
    "        n_batches = X.shape[0] / batch_size\n",
    "        losses = np.zeros(shape=(n_epoches, n_batches), dtype='float32')\n",
    "        for epoch in xrange(n_epoches):\n",
    "            #print epoch\n",
    "            for i, indx in enumerate(self.batch_stream(X.shape[0], batch_size=batch_size)):\n",
    "                losses[epoch, i] = self.train(X[indx], learning_rate)\n",
    "            yield losses[:(epoch + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretraining loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(deep_net.layers[1:len(deep_net.layers)-1]):\n",
    "    vae = VAE(l, p=0.25, X_input=deep_net.X_batch)\n",
    "    lozz = []\n",
    "    for l in vae.fit(X, n_epoches=8, batch_size=512, learning_rate=1.0):\n",
    "        lozz.append(l.mean())\n",
    "    #deep_net.copy_as_prior()\n",
    "    #deep_net.save('deep-net-%d.npz' % (i + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deep_net.load('deep-net-2.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lozz = []\n",
    "for l in deep_net.fit(X, y, n_epoches=8, batch_size=512, learning_rate=1.0e-1, regularization_coef=1.0e-2):\n",
    "    lozz.append(l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lozz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, training goes faster in case of using VAE as pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of the final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = theano.function([deep_net.X_batch], deep_net.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "y_proba = predict(X_test)\n",
    "print 'accuracy:', np.mean(np.argmax(y_test, axis=1) == np.argmax(y_proba, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
